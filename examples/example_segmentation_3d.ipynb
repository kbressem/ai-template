{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple training for 3d segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainlib.trainer import SegmentationTrainer\n",
    "from trainlib.utils import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "In `trainlib` everything is build around a config file. \n",
    "This makes training portable, e.g. between a workstation and a computing cluster. \n",
    "To change the training, the config needs to be adapted. \n",
    "Understanding the logic of the config and how it influences the training is crucial. \n",
    "We use a config file from unit tests as example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"../tests/test_config_segm.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "data:\n",
    "  data_dir: ../data/\n",
    "  train_csv: ../data/test_data_train_3d_segm.csv\n",
    "  valid_csv: ../data/test_data_valid_3d_segm.csv\n",
    "  test_csv: ../data/test_data_valid_3d_segm.csv\n",
    "  image_cols: [image]\n",
    "  label_cols: [label]\n",
    "  train: True\n",
    "  valid: True\n",
    "  test: False\n",
    "  dataset_type: persistent\n",
    "  cache_dir: .monai-cache\n",
    "  batch_size: 1\n",
    "```\n",
    "Trainlib uses CSV as API for filenames. As key concept, the CSV will provide the filename to the data, relative to `data_dir`. \n",
    "In this example the data_dir is `../data/` (absolute paths are recommended), the first filename of `train_csv` would be `images/radiopaedia_10_85902_1.nii.gz`. \n",
    "So `trainlib` will try to load the file from `/../data/images/radiopaedia_10_85902_1.nii.gz`. \n",
    "\n",
    "`image_cols` provide the col-name in the respective train/valid/test csv. Multiple names are possible. `label_cols` are treated the same.  \n",
    "`train: true` means, a train dataloader is constructed from `train_csv`.  \n",
    "`dataset_type: persistent` makes `trainlib` use `monai.data.PersistentDataset`, a dataset that caches files to disk for significant speedup during training. \n",
    "Especially for 3D i/o can become a major bottleneck of the training.   \n",
    "`cache_dir` gives the directory `trainlib` caches to. This is not deleted after training and can get quite large!  \n",
    "`batch_size` is the batch_size used during training. \n",
    "\n",
    "```yaml\n",
    "seed: 42\n",
    "debug: false\n",
    "device: cuda:0\n",
    "run_id: runs/heart-devices\n",
    "overwrite: true\n",
    "log_dir: logs\n",
    "out_dir: output\n",
    "ndim: 2\n",
    "model_dir: models\n",
    "```\n",
    "\n",
    "`seed` the random seed used throughout all trainlib.  \n",
    "`debug` `trainlib` provides a debug mode, which can be toggled on/off in the config.  \n",
    "`device` sets the hardware accelerator. `cpu` is also possible. Parallel training is not yet supported.   \n",
    "`run_id` The id of the trainings run. This will become a folder where everything is stored in. It is recommended that `runs/some-name` is used, so `runs` can be conviniently added to `.gitignore`  \n",
    "`overwrite` will overwrite the run_id or create a new one each run.  \n",
    "`log_dir` writes logs to `run_id/log_dir`. Logs are loss, metrics and snapshots from the training.  \n",
    "`out_dir` writes output to `run_id/out_dir`. Outputs are metrics. For segmentation this is Dice coefficient, Hausdorff distance, Surface distance.  \n",
    "`model_dir` `trainlib` places checkpoints in this directory (and also tries to load from here).  \n",
    "`ndim` the dimensionality of the data. 2 for 2d and 3 for 3d are supported.   \n",
    "\n",
    "```yaml\n",
    "loss:\n",
    "  DiceLoss:\n",
    "    include_background: true\n",
    "    softmax: true\n",
    "    to_onehot_y: true\n",
    "optimizer:\n",
    "  Adam:\n",
    "    lr: 0.01\n",
    "    weight_decay: 0.001\n",
    "lr_scheduler:\n",
    "  OneCycleLR:\n",
    "    max_lr: 0.0001\n",
    "model:\n",
    "  UNet:\n",
    "    act: PRELU\n",
    "    channels: [16, 32]\n",
    "    dropout: 0.1\n",
    "    norm: BATCH\n",
    "    num_res_units: 1\n",
    "    out_channels: 2 # bg, label\n",
    "    strides: [2]\n",
    "```\n",
    "Loss function and optimizer are parsed directly from `monai.losses` / `torch.nn` or `monai.optimizers` / `torch.optim`.   \n",
    "Models are loaded from `monai.network.nets`.  \n",
    "Number of input channels is parsed automatically from the number of input images (`len(image_cols)`), the rest is parsed to the monai class.  \n",
    "All arguments for `model` are directly parsed to monai, except `in_channels`, which is automatically derived from the length of `data.image_cols`.  \n",
    "\n",
    "```yaml\n",
    "training:\n",
    "  early_stopping_patience: 10\n",
    "  max_epochs: 25\n",
    "```\n",
    "`early_stopping_patience` controlls how long `trainlib` tollerates that the key metrics does not improve until trainig is stopped prematurely.  \n",
    "`max_epochs` max numbe of training epochs.  \n",
    "\n",
    "```yaml\n",
    "transforms:\n",
    "  base:\n",
    "    LoadImaged:\n",
    "      allow_missing_keys: true\n",
    "    EnsureChannelFirstd:\n",
    "      allow_missing_keys: true\n",
    "    Spacingd:\n",
    "      pixdim: [2, 2, 2]\n",
    "      mode: [bilinear, nearest]\n",
    "   train:\n",
    "     Identityd:\n",
    "   valid:\n",
    "     Identityd:\n",
    "   postprocessing: \n",
    "     Identityd:\n",
    "  prob: 0.1\n",
    "```\n",
    "`trainlib` uses different transforms pipelines: \n",
    "\n",
    "- `base` is always applied to the data. Use this for I/O and normalization. \n",
    "- `train` is just applied to the training data. Use this for augmentations. \n",
    "- `valid` is just applied to the validataion data.  \n",
    "- `postprocessing` is applied to the labels and predictions, after the loss but before the metrics are calculated. \n",
    "    \n",
    "`prob` controlls the probability that each transform is applied. \n",
    "If not explicitly stated with `key:`, each transform will be applied to each item in the data. \n",
    "\n",
    "```yaml\n",
    "patch:\n",
    "  transforms: /path/to/custom/transforms.py\n",
    "  model: /path/to/custom/model.py\n",
    "  loss: /path/to/custom/loss.py\n",
    "  optimizer: /path/to/custom/optimizer.py\n",
    "```\n",
    "Sometimes one needs to use custom code for transforms, models, loss or optimizer. For this `trainlib` uses patch-functionality. \n",
    "`trainlib` will try to load transforms/models/loss/optimizers from the patch-file first, then fall back to monai/torch. This way transforms can be overwritten or custom transforms can be used. \n",
    "\n",
    "\n",
    "```yaml\n",
    "pushover_credentials: /path/to/.pushover_credentials.yaml\n",
    "```\n",
    "Provide a file with pushover credentials to get updates on your mobile device. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple training and data inspection\n",
    "For this project, the `SegmentationTrainer` is used and the class is initialized from the config file. \n",
    "It is possible to override arguments in the config before passing it to the trainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setuptools is replacing distutils.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 10:21:33,727 - No pushover credentials file submitted, will not try to push trainings progress to pushover device. If you want to receive status updated via pushover, provide the path to a yaml file, containing the `app_token`, `user_key` and `proxies` (optional) in the config at `pushover_credentials`\n"
     ]
    }
   ],
   "source": [
    "trainer = SegmentationTrainer(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `show_batch`, `trainlib` provides a tool for quick visualization of the data. Data seen here, is passed directly to the model. \n",
    "Because `ipywidgets` are used, the output is interactive and not visible once the notebook is shutdown. Masks can be toggled on/off and intensities can be changed. \n",
    "```python\n",
    "trainer.data_loader.show_batch()\n",
    "```\n",
    "![Show Batch Example](figures/example-show-batch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_batch` uses `trainlib.viewer.ListViewer` to visualize output. But this class, as well as relatec classes can also be used directly in interactive sessions. \n",
    "Monai re-orients images to comply with the NIfTI header. It might be therefore nessecary to re-arrange the array before viewing. Here, this is done by transposing the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainlib.viewer import BasicViewer, ListViewer, DicomExplorer\n",
    "from monai.transforms import LoadImage\n",
    "\n",
    "reader = LoadImage(image_only=True)\n",
    "image_1 = reader(\"../data/images/radiopaedia_10_85902_1.nii.gz\").transpose(0, 2)\n",
    "image_2 = reader(\"../data/images/radiopaedia_10_85902_3.nii.gz\").transpose(0, 2)\n",
    "\n",
    "label_1 = reader(\"../data/labels/radiopaedia_10_85902_1.nii.gz\").transpose(0, 2)\n",
    "label_2 = reader(\"../data/labels/radiopaedia_10_85902_3.nii.gz\").transpose(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BasicViewer` can show a single image, with mask overlay or classification label. An optional description can also be added to the plot. \n",
    "\n",
    "```python\n",
    "BasicViewer(image_1, label_1, description=\"A CT showing COVID Pneumonia\").show()\n",
    "```\n",
    "![Show Batch Example](figures/example-basic-viewer-3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DicomExplorer` class provides additional information about the pixel/voxel values in the image array. \n",
    "\n",
    "```python\n",
    "DicomExplorer(image_1, label_1, description=\"A CT showing COVID Pneumonia\").show()\n",
    "```\n",
    "![Show Batch Example](figures/example-dicom-explorer-3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the `ListViewer` class allows to view multiple arrays at once. \n",
    "Here, each display is an individual instance of `BasicViewer`, so it is possible to mix images with/without masks/labels/descriptions and also show 2d and 3d images at the same time. \n",
    "\n",
    "```python\n",
    "ListViewer([image_1, image_2], [label_1, label_2]).show()\n",
    "```\n",
    "\n",
    "![Show Batch Example](figures/example-list-viewer-3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last check before training\n",
    "With sanity check, trainlib also provide a tool to test of all transforms can be applied without errors. Simple summary statistics about the labels are provided after the check. This way, you may catch errors early and not at the end of an two hour epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 10:43:05,396 - Frequency of label values:\n",
      "2022-11-18 10:43:05,397 - Value 0.0 appears in 3 items in the dataset\n",
      "2022-11-18 10:43:05,398 - Value 1.0 appears in 3 items in the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 10:43:05,961 - Frequency of label values:\n",
      "2022-11-18 10:43:05,962 - Value 0.0 appears in 2 items in the dataset\n",
      "2022-11-18 10:43:05,963 - Value 1.0 appears in 2 items in the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.data_loader.sanity_check()\n",
    "trainer.evaluator.data_loader.sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "After everything has been configured in the YAML file and data was checked, start training simply with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 10:24:15] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 10:24:17] We saw that you have a Intel(R) Core(TM) i5-8279U CPU @ 2.40GHz but we don't know it. Please contact us.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 10:24:20,886 - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
      "2022-11-18 10:24:28,525 - Epoch: 1/1, Iter: 1/3 -- train_loss: 0.6676 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/3]  33%|###3       [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 10:24:29,236 - Epoch: 1/1, Iter: 2/3 -- train_loss: 0.6667 \n",
      "2022-11-18 10:24:29,421 - Epoch: 1/1, Iter: 3/3 -- train_loss: 0.6548 \n",
      "2022-11-18 10:24:29,426 - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/2]  50%|#####      [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 10:24:39,147 - Got new best metric of val_mean_dice: 0.008058685809373856\n",
      "2022-11-18 10:24:39,708 - Epoch[1] Complete. Time taken: 00:00:10.183\n",
      "2022-11-18 10:24:39,709 - Engine run complete. Time taken: 00:00:10.282\n",
      "2022-11-18 10:24:49,717 - Key metric: None best value: -1 at epoch: -1\n",
      "2022-11-18 10:24:49,718 - Key metric: None best value: -1 at epoch: -1\n",
      "2022-11-18 10:24:49,719 - Epoch[1] Complete. Time taken: 00:00:28.746\n",
      "2022-11-18 10:24:49,721 - Engine run complete. Time taken: 00:00:28.834\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainlib is not primarily designed for notebooks. While data analysis and checking should be done in notebooks, the final training is better carried out using a simple training script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trainlib` uses logging, which allows to control the verbosity of the trainier. Per default, the log-level is `INFO`. \n",
    "The loggers can be accessed at `trainer.logger` and `trainer.evaluator.logger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "61d67c5a887374fe4528bc1bcc3d29c8726e2993ddef9e70ac79ae4bf310a5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
