run_id: runs/name # creates folders run/name where all produced output (e.g. logs) is stored
overwrite: true # overwrite the above specified folders when training is restarted. Otherwise, create new folder
debug: false # enable/disable debug
device: cuda:0
# Set dirs for logs, models and generic output, such as metrics
log_dir: logs
model_dir: models
out_dir: output
ndim: 3 # Image dimensions
seed: 42 # set seed for determinism.
# data confidurations
data:
  data_dir: /paht/where/data/is/stored
  train_csv: train.csv # should give paths to files, relative to `data_dir`
  valid_csv: valid.csv
  test_csv: test.csv
  # col names of the image and label files. Pass multiple names as list
  image_cols: [image_1, image_2]
  label_cols: label
  train: True # Use trainig dataset
  valid: True
  test: False
  dataset_type: persistent # iterative or persistend (chaches transforms on disk for large speedup)
  cache_dir: .monai-cache # cache dir for persistent dataset, otherwise ignored
  batch_size: 1
# Use every loss function from monai.losses
loss:
  DiceFocalLoss:
    include_background: true
    softmax: true
    to_onehot_y: true
# Applies one-cycle policy to learning rate
lr_scheduler:
  OneCycleLR:
    max_lr: 0.0001
# Create standard U-ResNet from monai.nets.networks.UNet
model:
  act: PRELU
  channels: [16, 32, 64, 128, 256, 512]
  dropout: 0.1
  norm: BATCH
  num_res_units: 3
  out_channels: 2 # bg, label
  strides: [2, 2, 2, 2, 1]
# Create optimizer from monai.optimizers
optimizer:
  Adam:
    lr: 0.0001
    weight_decay: 0.001
training:
  early_stopping_patience: 250
  max_epochs: 1500
# Create transforms pipeline.
# base: applied to train/valid/test data. Use this for general image normalization
# train: only applied to train data, use this for augmentation.
# valid: only applied to valid data
transforms:
  prob: 0.1
  mode: [bilinear, nearest]
  base:
    Spacingd:
      pixdim: [1, 1, 1]
  train:
    CustomPatchedTransform:
      arg1: some_value
      arg2: some_other_value
    RandCropByPosNegLabeld:
      label_key: label
      neg: 2
      num_samples: 6
      pos: 1
      spatial_size: [96, 96, 96]
# Monkey-patch different functionalities of trainlib
# transforms:
#   Allows to specify custom transforms. Should be based on monai transforms.
#   Will override any default transforms in trainlib pipelines
# model:
#   Should provide a get_model function that is called to create a custom model.
#   Overwrites above specified U-ResNet
# loss:
#   Should provide a get_loss function. Overwrites above specified loss
# optimizer:
#   Should provide a get_optimizer function. Overwrites above specified optimizer
patch:
  transforms: path/to/patch/transforms.py # to load CustomPatchedTransform from
# Provide API-key and personal-key in credential file to recieve training updates after every epoch
pushover_credentials: /path/to/.pushover_credentials.yaml
